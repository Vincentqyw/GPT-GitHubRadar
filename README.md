<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#chatgpt>chatgpt</a></li>
    <li><a href=#segment-anything>segment anything</a></li>
    <li><a href=#llama>llama</a></li>
  </ol>
</details>

## Chatgpt
- Sort by: Stars

| Name | Description | Stars | Updated |
| --- | --- | --- | --- |
| [gpt_academic](https://github.com/binary-husky/gpt_academic) | ä¸ºGPT/GLMæä¾›å›¾å½¢äº¤äº’ç•Œé¢ï¼Œç‰¹åˆ«ä¼˜åŒ–è®ºæ–‡é˜…è¯»æ¶¦è‰²ä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡æ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®&å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒä»£ç å—è¡¨æ ¼æ˜¾ç¤ºï¼ŒTexå…¬å¼åŒæ˜¾ç¤ºï¼Œæ–°å¢Pythonå’ŒC++é¡¹ç›®å‰–æ&è‡ªè¯‘è§£åŠŸèƒ½ï¼ŒPDF/LaTexè®ºæ–‡ç¿»è¯‘&æ€»ç»“åŠŸèƒ½ï¼Œæ”¯æŒå¹¶è¡Œé—®è¯¢å¤šç§LLMæ¨¡å‹ï¼Œæ”¯æŒæ¸…åchatglmç­‰æœ¬åœ°æ¨¡å‹ã€‚å…¼å®¹llama,rwkv,ç›˜å¤å¤§æ¨¡å‹ç­‰ã€‚ | 31835 | 2023-05-05-02:30:01 |
| [gpt4free](https://github.com/xtekky/gpt4free) | decentralising the Ai Industry, just some language model api's... | 29506 | 2023-05-05-02:30:24 |
| [ChatGPT-Next-Web](https://github.com/Yidadaa/ChatGPT-Next-Web) | One-Click to deploy well-designed ChatGPT web UI on Vercel. ä¸€é”®æ‹¥æœ‰ä½ è‡ªå·±çš„ ChatGPT ç½‘é¡µæœåŠ¡ã€‚ | 22379 | 2023-05-05-02:30:19 |
| [chatgpt-web](https://github.com/Chanzhaoyu/chatgpt-web) | ç”¨ Express å’Œ  Vue3 æ­å»ºçš„ ChatGPT æ¼”ç¤ºç½‘é¡µ | 20834 | 2023-05-05-02:29:37 |
| [chatgpt-retrieval-plugin](https://github.com/openai/chatgpt-retrieval-plugin) | The ChatGPT Retrieval Plugin lets you easily search and find personal or work documents by asking questions in everyday language. | 15694 | 2023-05-05-02:19:36 |
| [openai-translator](https://github.com/yetone/openai-translator) | åŸºäº ChatGPT API çš„åˆ’è¯ç¿»è¯‘æµè§ˆå™¨æ’ä»¶å’Œè·¨å¹³å°æ¡Œé¢ç«¯åº”ç”¨    -    Browser extension and cross-platform desktop application for translation based on ChatGPT API. | 15504 | 2023-05-05-02:26:09 |
| [chatbot-ui](https://github.com/mckaywrigley/chatbot-ui) | An open source ChatGPT UI. | 12842 | 2023-05-05-02:24:47 |
| [ChatPaper](https://github.com/kaixindelele/ChatPaper) | Use ChatGPT to summarize the arXiv papers. å…¨æµç¨‹åŠ é€Ÿç§‘ç ”ï¼Œåˆ©ç”¨chatgptè¿›è¡Œè®ºæ–‡æ€»ç»“+æ¶¦è‰²+å®¡ç¨¿+å®¡ç¨¿å›å¤ | 10983 | 2023-05-05-02:15:02 |
| [carrot](https://github.com/xx025/carrot) | Free ChatGPT Site List è¿™å„¿ä¸ºä½ å‡†å¤‡äº†ä¼—å¤šå…è´¹å¥½ç”¨çš„ChatGPTé•œåƒç«™ç‚¹ï¼Œå½“å‰100+ç«™ç‚¹ | 10213 | 2023-05-05-02:25:53 |
| [chatbox](https://github.com/Bin-Huang/chatbox) | Your Ultimate Copilot on the Desktop. Chatbox is a desktop app for GPT-4 / GPT-3.5 (OpenAI API) that supports Windows, Mac & Linux. | 10160 | 2023-05-05-02:30:04 |
| [ChuanhuChatGPT](https://github.com/GaiZhenbiao/ChuanhuChatGPT) | GUI for ChatGPT API and any LLM | 9969 | 2023-05-05-02:23:43 |
| [MOSS](https://github.com/OpenLMLab/MOSS) | An open-source tool-augmented conversational language model from Fudan University | 9371 | 2023-05-05-02:27:02 |
| [chatGPTBox](https://github.com/josStorer/chatGPTBox) | Integrating ChatGPT into your browser deeply, everything you need is here | 7333 | 2023-05-05-02:22:31 |
| [KeepChatGPT](https://github.com/xcanwin/KeepChatGPT) | ChatGPTç•…èŠæ’ä»¶ã€‚è§£å†³æ‰€æœ‰æŠ¥é”™ï¼Œè®©æˆ‘ä»¬çš„AIä½“éªŒæ— æ¯”é¡ºç•…ã€ä¸æ»‘ã€é«˜æ•ˆã€‚æŒç»­æ›´æ–°çš„å¢å¼ºåŠŸèƒ½ï¼Œå¦‚å–æ¶ˆå®¡è®¡ç­‰ã€‚è§£å†³çš„æŠ¥é”™å¦‚ä¸‹: (1) NetworkError when attempting to fetch resource. (2) Something went wrong. If this issue persists please contact us through our help center at help.openai.com. (3) Conversation not found. (4) This content may violate our content policy. | 7196 | 2023-05-05-02:24:38 |
| [BingGPT](https://github.com/dice2o/BingGPT) | Desktop application of new Bing's AI-powered chat (Windows, macOS and Linux) | 6802 | 2023-05-05-02:25:54 |
| [chatgpt-demo](https://github.com/anse-app/chatgpt-demo) | Minimal UI for ChatGPT.  | 6795 | 2023-05-05-01:47:47 |
| [ChatRWKV](https://github.com/BlinkDL/ChatRWKV) | ChatRWKV is like ChatGPT but powered by RWKV (100% RNN) language model, and open source. | 6542 | 2023-05-05-02:23:07 |
| [EdgeGPT](https://github.com/acheong08/EdgeGPT) | Reverse engineered API of Microsoft's Bing Chat AI | 6299 | 2023-05-05-02:09:21 |
| [langflow](https://github.com/logspace-ai/langflow) | â›“ï¸ LangFlow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows. | 5977 | 2023-05-05-02:19:01 |
| [awesome-chatgpt-zh](https://github.com/yzfly/awesome-chatgpt-zh) | ChatGPT ä¸­æ–‡æŒ‡å—ğŸ”¥ï¼ŒChatGPT ä¸­æ–‡è°ƒæ•™æŒ‡å—ï¼ŒæŒ‡ä»¤æŒ‡å—ï¼Œç²¾é€‰èµ„æºæ¸…å•ï¼Œæ›´å¥½çš„ä½¿ç”¨ chatGPT è®©ä½ çš„ç”Ÿäº§åŠ› up up up! ğŸš€ | 5655 | 2023-05-05-02:28:32 |
| [web-llm](https://github.com/mlc-ai/web-llm) | Bringing large-language models and chat to web browsers. Everything runs inside the browser with no server support. | 5180 | 2023-05-05-02:25:46 |
| [LMFlow](https://github.com/OptimalScale/LMFlow) | An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All. | 4988 | 2023-05-05-02:25:09 |
| [shell_gpt](https://github.com/TheR1D/shell_gpt) | A command-line productivity tool powered by ChatGPT, will help you accomplish your tasks faster and more efficiently. | 4677 | 2023-05-04-21:25:54 |
| [bob-plugin-openai-translator](https://github.com/yetone/bob-plugin-openai-translator) | åŸºäº ChatGPT API çš„æ–‡æœ¬ç¿»è¯‘ã€æ–‡æœ¬æ¶¦è‰²ã€è¯­æ³•çº é”™ Bob æ’ä»¶ï¼Œè®©æˆ‘ä»¬ä¸€èµ·è¿æ¥ä¸éœ€è¦å·´åˆ«å¡”çš„æ–°æ—¶ä»£ï¼ | 4604 | 2023-05-05-02:30:13 |
| [awesome-chatgpt-api](https://github.com/reorx/awesome-chatgpt-api) | Curated list of apps and tools that not only use the new ChatGPT API, but also allow users to configure their own API keys, enabling free and on-demand usage of their own quota. | 4490 | 2023-05-05-00:16:23 |
| [Feishu-OpenAI](https://github.com/ConnectAI-E/Feishu-OpenAI) | ğŸ’é£ä¹¦  Ã—ï¼ˆGPT-3.5 + DALLÂ·E + Whisperï¼‰=  é£ä¸€èˆ¬çš„å·¥ä½œä½“éªŒ  ğŸš€ è¯­éŸ³å¯¹è¯ã€è§’è‰²æ‰®æ¼”ã€å¤šè¯é¢˜è®¨è®ºã€å›¾ç‰‡åˆ›ä½œã€è¡¨æ ¼åˆ†æã€æ–‡æ¡£å¯¼å‡º ğŸš€ | 4087 | 2023-05-05-01:05:39 |
| [ChatGPT-Shortcut](https://github.com/rockbenben/ChatGPT-Shortcut) | Maximize your efficiency and productivity. è®©ç”Ÿäº§åŠ›åŠ å€çš„ ChatGPT å¿«æ·æŒ‡ä»¤ï¼ŒæŒ‰ç…§é¢†åŸŸå’ŒåŠŸèƒ½åˆ†åŒºï¼Œå¯å¯¹æç¤ºè¯è¿›è¡Œæ ‡ç­¾ç­›é€‰ã€å…³é”®è¯æœç´¢å’Œä¸€é”®å¤åˆ¶ã€‚ | 3936 | 2023-05-05-01:53:59 |
| [myGPTReader](https://github.com/madawei2699/myGPTReader) | A community-driven way to read and chat with AI bots - powered by chatGPT. | 3850 | 2023-05-05-01:34:31 |
| [awesome-totally-open-chatgpt](https://github.com/nichtdax/awesome-totally-open-chatgpt) | A list of totally open alternatives to ChatGPT | 3644 | 2023-05-05-01:59:21 |
| [BetterChatGPT](https://github.com/ztjhz/BetterChatGPT) | An amazing UI for OpenAI's ChatGPT (Website + Windows + MacOS + Linux) | 3609 | 2023-05-05-02:27:39 |
- Sort by: Updated

| Name | Description | Stars | Updated |
| --- | --- | --- | --- |
| [pyqt-openai](https://github.com/yjg30737/pyqt-openai) | Using OpenAI with PyQt (Python cross-platform GUI toolkit) | 15 | 2023-05-03-12:09:33 |
| [wx-tmy-prompt](https://github.com/fnw-tools/wx-tmy-prompt) | Room and prompt definition for chatGPT in WeChat | 0 | 2023-04-28-14:22:29 |
| [ChatGPTPromptEngineering](https://github.com/petrubear/ChatGPTPromptEngineering) | None | 0 | 2023-05-05-01:53:13 |
| [autobabytermux](https://github.com/rocket-pig/autobabytermux) | chatGPT 'Autonomous Agent' in Node.js, written/runs in Termux. Sandboxed REPL access and chain-of-thought Question-Observation-Thought-Action-Result reasoning. All in 400 lines of js | 0 | 2023-05-05-02:27:03 |
| [gptchars](https://github.com/dubesor/gptchars) | GPT-Chars | 0 | 2023-05-02-23:17:22 |
| [Maiya-ChatGPT-Experiments](https://github.com/vbookshelf/Maiya-ChatGPT-Experiments) | My experiments with ChatGPT | 0 | 2023-04-09-12:02:10 |
| [AiTreasureBox](https://github.com/superiorlu/AiTreasureBox) | ğŸ¤– Collect practical AI repos, tools, websites, papers and tutorials on AI. å®ç”¨çš„AIç™¾å®ç®± ğŸ’  | 92 | 2023-05-03-19:09:14 |
| [chatgpt-frontend](https://github.com/TrdDAO/chatgpt-frontend) | None | 0 | 2023-04-12-05:52:41 |
| [Proyecto_500k_tweets_chatGPT](https://github.com/AguirreMariaHerminia/Proyecto_500k_tweets_chatGPT) | None | 0 | 2023-05-05-02:06:04 |
| [wechat-chatgpt](https://github.com/a347807131/wechat-chatgpt) | None | 0 | 2023-05-05-02:26:13 |
| [ChatGPT-Web](https://github.com/summer0102/ChatGPT-Web) | None | 0 | 2023-05-05-02:25:20 |
| [chatgpt-0x](https://github.com/zhuchentong/chatgpt-0x) | None | 0 | 2023-04-11-21:08:43 |
| [chatMANipulation](https://github.com/frrobot-ai/chatMANipulation) | â€œè®©ChatGPTå¸®æˆ‘ä»¬ç”Ÿæˆæœºå™¨äººæ§åˆ¶æŒ‡ä»¤å§ã€‚â€ | 0 | 2023-05-04-08:49:27 |
| [ChatVox](https://github.com/JimmyLv/ChatVox) | "Chat With Any Video" project in 24 hours, challenge myself to complete in @Supabase's AI Hackathon. | 56 | 2023-05-04-20:49:33 |
| [feishu-chatgpt](https://github.com/kiokit/feishu-chatgpt) | None | 0 | 2023-05-05-02:23:17 |
| [Quasar](https://github.com/HansonASU/Quasar) | A command line ChatGPT client written in Rust | 0 | 2023-05-03-23:30:55 |
| [LLaVA](https://github.com/haotian-liu/LLaVA) | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. | 2149 | 2023-05-05-02:02:26 |
| [chatgptcode](https://github.com/songlihuan/chatgptcode) | None | 0 | 2023-04-10-15:36:29 |
| [ChatGPT-Next-Web-Latest](https://github.com/aiesst/ChatGPT-Next-Web-Latest) | None | 0 | 2023-05-04-11:36:59 |
| [vtbai](https://github.com/newreport/vtbai) | ai liveï¼Œai vtbï¼Œbilibili live with chatgptï¼ŒåŸºäºchatgptåç«¯è¿›è¡Œaiç›´æ’­ï¼Œé…åˆobså’Œvtsï¼Œéœ€è¦å›¾å½¢åŒ–ç•Œé¢ | 35 | 2023-05-04-10:10:10 |
| [wechat-chatgpt](https://github.com/Hero2333/wechat-chatgpt) | None | 0 | 2023-05-05-02:19:46 |
| [ChatGPT-Web-0501](https://github.com/Michael5chao/ChatGPT-Web-0501) | None | 0 | 2023-05-01-13:26:44 |
| [Interactive-ChatGPT-CLI](https://github.com/amazingpaddy/Interactive-ChatGPT-CLI) | An interactive CLI for real-time conversations with OpenAI's ChatGPT, supporting multiple modes and models with optional memory management for enhanced user experience. | 0 | 2023-04-20-01:12:02 |
| [feishu-chatgpt3](https://github.com/RainyMask/feishu-chatgpt3) | None | 0 | 2023-05-05-02:19:28 |
| [chatgpt-index-bot](https://github.com/kenchin110100/chatgpt-index-bot) | LammaIndexã®Indexã‚µãƒ¼ãƒæ©Ÿèƒ½ã‚’åˆ©ç”¨ã—ãŸslackãƒœãƒƒãƒˆ | 0 | 2023-05-02-08:12:02 |
| [chatgpt-wrapper](https://github.com/tbennett6421/chatgpt-wrapper) | I wanted to wrap the api in a python script instead of using the browser. Just an exercise in coding | 0 | 2023-05-05-02:17:46 |
| [wechat-chatGPT](https://github.com/dunk-code/wechat-chatGPT) | None | 4 | 2023-04-05-05:28:28 |
| [GPT-AI](https://github.com/Pranav00747/GPT-AI) | Why should I share if hacker will hack simply trained machine learning & AI. {{ (defn _chatGPT[gpt]( if(gpt=="different vers"))) }} | 0 | 2023-03-05-18:51:17 |
| [OpenAIOnWPF](https://github.com/yt3trees/OpenAIOnWPF) | WPF application to operate OpenAI API | 0 | 2023-04-02-08:22:00 |
| [ChatGPT_UdemyCourse](https://github.com/fullstackdev710/ChatGPT_UdemyCourse) | ChatGPT Udemy Courses | 0 | 2023-05-05-02:16:46 |
## Segment Anything
- Sort by: Stars

| Name | Description | Stars | Updated |
| --- | --- | --- | --- |
| [segment-anything](https://github.com/facebookresearch/segment-anything) | The repository provides code for running inference with the SegmentAnything Model (SAM), links for downloading the trained model checkpoints, and example notebooks that show how to use the model. | 31306 | 2023-05-05-02:30:02 |
| [Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything) | Marrying Grounding DINO with Segment Anything & Stable Diffusion & Tag2Text & BLIP & Whisper & ChatBot - Automatically Detect , Segment and Generate Anything with Image, Text, and Audio Inputs | 7914 | 2023-05-05-02:30:24 |
| [Track-Anything](https://github.com/gaomingqi/Track-Anything) | Track-Anything is a flexible and interactive tool for video object tracking and segmentation, based on Segment Anything, XMem, and E2FGVI. | 3830 | 2023-05-05-02:29:24 |
| [Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything) | Inpaint anything using Segment Anything and inpainting models. | 2808 | 2023-05-05-02:26:35 |
| [magic-copy](https://github.com/kevmo314/magic-copy) | Magic Copy is a Chrome extension that uses Meta's Segment Anything Model to extract a foreground object from an image and copy it to the clipboard. | 1790 | 2023-05-05-02:03:52 |
| [EditAnything](https://github.com/sail-sg/EditAnything) | Edit anything in images  powered by segment-anything, ControlNet, StableDiffusion, etc. | 1755 | 2023-05-05-01:33:48 |
| [sd-webui-segment-anything](https://github.com/continue-revolution/sd-webui-segment-anything) | Segment Anything for Stable Diffusion WebUI | 1144 | 2023-05-05-01:01:24 |
| [Semantic-Segment-Anything](https://github.com/fudan-zvg/Semantic-Segment-Anything) | Automated dense category annotation engine that serves as the initial semantic labeling for the Segment Anything dataset (SA-1B).  | 1135 | 2023-05-04-19:28:36 |
| [Segment-and-Track-Anything](https://github.com/z-x-yang/Segment-and-Track-Anything) | An open-source project dedicated to tracking and segmenting any objects in videos, either automatically or interactively. The primary algorithms utilized include the Segment Anything Model (SAM) for key-frame segmentation and Associating Objects with Transformers (AOT) for efficient tracking and propagation purposes. | 946 | 2023-05-04-23:47:15 |
| [Anything-3D](https://github.com/Anything-of-anything/Anything-3D) | Segment-Anything + 3D. Let's lift anything to 3D. | 914 | 2023-05-05-01:47:57 |
| [segment-geospatial](https://github.com/opengeos/segment-geospatial) | A Python package for segmenting geospatial data with the Segment Anything Model (SAM) | 753 | 2023-05-05-02:27:52 |
| [salt](https://github.com/anuragxel/salt) | Segment Anything Labelling Tool | 715 | 2023-05-05-01:24:07 |
| [segment-anything-video](https://github.com/kadirnar/segment-anything-video) | MetaSeg: Packaged version of the Segment Anything repository | 584 | 2023-05-04-17:30:34 |
| [Image2Paragraph](https://github.com/showlab/Image2Paragraph) | [A toolbox for fun.] Transform Image into Unique Paragraph with ChatGPT, BLIP2, OFA, GRIT, Segment Anything, ControlNet. | 551 | 2023-05-04-14:19:28 |
| [anylabeling](https://github.com/vietanhdev/anylabeling) | Effortless AI-assisted data labeling with AI support from Segment Anything and YOLO! | 471 | 2023-05-05-00:06:28 |
| [MedSAM](https://github.com/bowang-lab/MedSAM) | The official repository for MedSAM: Segment Anything in Medical Images. | 384 | 2023-05-05-01:47:27 |
| [awesome-segment-anything](https://github.com/Hedlen/awesome-segment-anything) | Tracking and collecting papers/projects/others related to Segment Anything. | 372 | 2023-05-05-02:07:02 |
| [3D-Box-Segment-Anything](https://github.com/dvlab-research/3D-Box-Segment-Anything) | We extend Segment Anything to 3D perception by combining it with VoxelNeXt. | 354 | 2023-05-04-09:17:44 |
| [SAM-Adapter-PyTorch](https://github.com/tianrun-chen/SAM-Adapter-PyTorch) | Adapting Meta AI's Segment Anything to Downstream Tasks with Adapters and Prompts | 304 | 2023-05-04-15:38:45 |
| [segment-anything-eo](https://github.com/aliaksandr960/segment-anything-eo) | Earth observation tools for Meta AI Segment Anything | 253 | 2023-05-04-00:34:27 |
| [SegmentAnythingin3D](https://github.com/Jumpat/SegmentAnythingin3D) | Segment Anything in 3D with NeRFs | 241 | 2023-05-04-23:57:11 |
| [grounded-segment-any-parts](https://github.com/Cheems-Seminar/grounded-segment-any-parts) | Grounded Segment Anything: From Objects to Parts | 219 | 2023-05-04-15:10:05 |
| [OCR-SAM](https://github.com/yeungchenwa/OCR-SAM) | Combining MMOCR with Segment Anything & Stable Diffusion. Automatically detect, recognize and segment text instances, with serval downstream tasks, e.g., Text Removal and Text Inpainting | 204 | 2023-05-04-13:22:19 |
| [lang-segment-anything](https://github.com/luca-medeiros/lang-segment-anything) | SAM with text prompt | 182 | 2023-05-05-01:52:18 |
| [awesome-segment-anything-extensions](https://github.com/JerryX1110/awesome-segment-anything-extensions) | Segment-anything related awesome extensions/projects/repos. | 178 | 2023-05-04-10:14:03 |
| [Segment-Anything-NeRF](https://github.com/ashawkey/Segment-Anything-NeRF) | Segment-anything interactively in NeRF. | 174 | 2023-05-05-00:30:22 |
| [ISAT_with_segment_anything](https://github.com/yatengLG/ISAT_with_segment_anything) | Image segmentation annotation tool with segment anything.ï¼ˆå›¾åƒåˆ†å‰²æ ‡æ³¨å·¥å…·ï¼Œæ”¯æŒè¯­ä¹‰åˆ†å‰²ä¸å®ä¾‹åˆ†å‰²ï¼Œé›†æˆsegment anythingï¼Œå®ç°å¿«é€Ÿå›¾åƒåˆ†å‰²æ ‡æ³¨ï¼‰ | 156 | 2023-05-04-18:15:21 |
| [segment-anything-with-clip](https://github.com/Curt-Park/segment-anything-with-clip) | Segment Anything combined with CLIP | 154 | 2023-05-04-14:13:12 |
| [Prompt-Segment-Anything](https://github.com/RockeyCoss/Prompt-Segment-Anything) | This is an implementation of zero-shot instance segmentation using Segment Anything. | 154 | 2023-05-04-18:13:12 |
| [segment-anything-annotator](https://github.com/haochenheheda/segment-anything-annotator) | We developed a python UI based on labelme and segment-anything for pixel-level annotation. It support multiple masks generation by SAM(box/point prompt),  efficient polygon modification and category record. We will add more features (such as incorporating CLIP-based methods for category proposal and VOS methods for video datasets | 148 | 2023-05-03-13:17:43 |
- Sort by: Updated

| Name | Description | Stars | Updated |
| --- | --- | --- | --- |
| [Awesome-Segment-Anything](https://github.com/Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything) | A collection of project, papers, and source code for Meta AI's Segment Anything Model (SAM) and related studies. | 52 | 2023-05-04-15:12:05 |
| [segment-anything](https://github.com/facebookresearch/segment-anything) | The repository provides code for running inference with the SegmentAnything Model (SAM), links for downloading the trained model checkpoints, and example notebooks that show how to use the model. | 31307 | 2023-05-05-02:30:47 |
| [segment-anything-ncnn](https://github.com/FeiGeChuanShu/segment-anything-ncnn) | an example of segment-anything infer by ncnn | 69 | 2023-05-04-07:39:00 |
| [onnx_segment_anything_experiments](https://github.com/tempdeltavalue/onnx_segment_anything_experiments) | onnx sam exps | 0 | 2023-05-04-20:38:41 |
| [segment-geospatial](https://github.com/opengeos/segment-geospatial) | A Python package for segmenting geospatial data with the Segment Anything Model (SAM) | 753 | 2023-05-05-02:27:52 |
| [segment-anything-ui](https://github.com/branislavhesko/segment-anything-ui) | Segment anything UI for annotations | 5 | 2023-04-26-22:29:48 |
| [Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds | 13 | 2023-05-05-02:23:31 |
| [Segment-Anything-Model-](https://github.com/diebrum/Segment-Anything-Model-) | None | 0 | 2023-05-02-20:56:17 |
| [say-anything-backend](https://github.com/suvansh/say-anything-backend) | backend for segment anything text prompt extension | 0 | 2023-04-23-10:42:57 |
| [segment-anything-services](https://github.com/developmentseed/segment-anything-services) | Running segment-anything image embedding, prompting, and mask generation as torchserve services | 26 | 2023-05-03-09:48:53 |
| [Segment-Anything-Model-for-Geospatial-otemachi-example](https://github.com/syu-tan/Segment-Anything-Model-for-Geospatial-otemachi-example) | Segment Anything Model for Geospatia lotemachi example for Japanese. | 1 | 2023-05-04-17:18:25 |
| [Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything) | Marrying Grounding DINO with Segment Anything & Stable Diffusion & Tag2Text & BLIP & Whisper & ChatBot - Automatically Detect , Segment and Generate Anything with Image, Text, and Audio Inputs | 7914 | 2023-05-05-02:30:24 |
| [anylabeling](https://github.com/vietanhdev/anylabeling) | Effortless AI-assisted data labeling with AI support from Segment Anything and YOLO! | 471 | 2023-05-05-00:06:28 |
| [Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything) | Inpaint anything using Segment Anything and inpainting models. | 2808 | 2023-05-05-02:26:35 |
| [EditAnything](https://github.com/sail-sg/EditAnything) | Edit anything in images  powered by segment-anything, ControlNet, StableDiffusion, etc. | 1755 | 2023-05-05-01:33:48 |
| [SAM](https://github.com/Raghvender1205/SAM) | Segment Anything Model (SAM) from Meta AI for Segmentation across Video, Image etc. | 1 | 2023-05-04-15:17:31 |
| [MedSAM](https://github.com/bowang-lab/MedSAM) | The official repository for MedSAM: Segment Anything in Medical Images. | 384 | 2023-05-05-01:47:27 |
| [SAM_service](https://github.com/JaneliaSciComp/SAM_service) | web service to supply segment_anything models, when provided with an image  | 0 | 2023-04-27-14:50:34 |
| [segment-anything-annotator](https://github.com/haochenheheda/segment-anything-annotator) | We developed a python UI based on labelme and segment-anything for pixel-level annotation. It support multiple masks generation by SAM(box/point prompt),  efficient polygon modification and category record. We will add more features (such as incorporating CLIP-based methods for category proposal and VOS methods for video datasets | 148 | 2023-05-03-13:17:43 |
| [segment_anything](https://github.com/Talgin/segment_anything) | Tests on segment anything | 0 | 2023-05-04-11:42:54 |
| [SegmentAnything.jl](https://github.com/rafaqz/SegmentAnything.jl) | segment-anything wrapped for Julia | 26 | 2023-05-04-17:15:55 |
| [Segment-Anything-CLIP](https://github.com/PengtaoJiang/Segment-Anything-CLIP) | Connecting segment-anything's output masks with the CLIP model; Awesome-Segment-Anything-Works | 54 | 2023-05-04-07:45:08 |
| [Cryo-Fidusial-Marker-with-Segment-Anything](https://github.com/Dylan8527/Cryo-Fidusial-Marker-with-Segment-Anything) | This is a simply a final project for SI363 Spring. | 1 | 2023-05-04-13:51:02 |
| [meta-sam-demo](https://github.com/MiscellaneousStuff/meta-sam-demo) | Meta's Segment Anything Model (SAM) Demo Site | 63 | 2023-05-03-10:20:04 |
| [SAM4MIS](https://github.com/YichiZhang98/SAM4MIS) | literature reviews of Segment Anything Model (SAM) for medical image segmentation | 1 | 2023-04-26-17:56:55 |
| [simple-semantic-segment-anything-annotator](https://github.com/KleinYuan/simple-semantic-segment-anything-annotator) | One line of code to use semantic-segment-anything to auto annotate your datasets | 2 | 2023-05-04-08:31:57 |
| [SAMLabelerPro](https://github.com/LSH9832/SAMLabelerPro) | label your image with Segment Anything Model, support remote labeling for multiple personsã€‚ä½¿ç”¨Segment Anything Modelè¾…åŠ©çš„æ ‡æ³¨å·¥å…·ï¼Œæ”¯æŒå¤šäººè¿œç¨‹æ ‡æ³¨ | 5 | 2023-05-04-03:28:10 |
| [scam](https://github.com/buda-base/scam) | segment and crop anything | 0 | 2023-05-03-15:29:10 |
| [Gaze-Segment-Anything-YCB-Video](https://github.com/alexcbb/Gaze-Segment-Anything-YCB-Video) | This project uses gaze information from VR-Headset to segment YCB objects from images.  | 0 | 2023-05-04-06:46:56 |
| [Awesome-SAM](https://github.com/baibizhe/Awesome-SAM) | This repo collects the research resources based on SAM(Segment Anything Model) proposed by Meta AI. If you would like to contribute, please open an issue. | 11 | 2023-05-05-01:20:22 |
## Llama
- Sort by: Stars

| Name | Description | Stars | Updated |
| --- | --- | --- | --- |
| [llama.cpp](https://github.com/ggerganov/llama.cpp) | Port of Facebook's LLaMA model in C/C++ | 25614 | 2023-05-05-02:22:52 |
| [alpaca-lora](https://github.com/tloen/alpaca-lora) | Instruct-tune LLaMA on consumer hardware | 11312 | 2023-05-05-02:27:46 |
| [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹+æœ¬åœ°CPU/GPUéƒ¨ç½² (Chinese LLaMA & Alpaca LLMs) | 7060 | 2023-05-05-02:29:06 |
| [BELLE](https://github.com/LianjiaTech/BELLE) | BELLE: Be Everyone's Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ | 4784 | 2023-05-05-02:14:22 |
| [serge](https://github.com/nsarrazin/serge) | A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API. | 3962 | 2023-05-05-01:49:54 |
| [lit-llama](https://github.com/Lightning-AI/lit-llama) | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. | 3022 | 2023-05-05-02:05:40 |
| [GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | Instruction Tuning with GPT-4 | 2426 | 2023-05-04-21:48:27 |
| [Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆï¼Œç»“æ„å‚è€ƒalpaca | 2208 | 2023-05-05-02:24:04 |
| [LLaVA](https://github.com/haotian-liu/LLaVA) | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. | 2149 | 2023-05-05-02:02:26 |
| [open_llama](https://github.com/openlm-research/open_llama) | None | 1977 | 2023-05-05-02:26:31 |
| [xturing](https://github.com/stochasticai/xturing) | Easily build, customize and control your own LLMs | 1745 | 2023-05-05-01:33:26 |
| [simple-llm-finetuner](https://github.com/lxe/simple-llm-finetuner) | Simple UI for LLM Model Finetuning | 1507 | 2023-05-04-19:36:12 |
| [Alpaca-CoT](https://github.com/PhoebusSi/Alpaca-CoT) | We extend CoT data to Alpaca to boost its reasoning ability. We are constantly expanding our collection of instruction-tuning data, and integrating more LLMs together for easy use. ï¼ˆæˆ‘ä»¬å°†CoTæ•°æ®æ‰©å±•åˆ°Alpacaä»¥æé«˜å…¶æ¨ç†èƒ½åŠ›ï¼ŒåŒæ—¶æˆ‘ä»¬å°†ä¸æ–­æ”¶é›†æ›´å¤šçš„instruction-tuningæ•°æ®é›†,å¹¶åœ¨æˆ‘ä»¬æ¡†æ¶ä¸‹é›†æˆè¿›æ›´å¤šçš„LLMï¼Œæ‰“é€ ä¸€ä¸ªé€šç”¨çš„LLM-IFTå¹³å°ã€‚ï¼‰ | 1321 | 2023-05-05-01:16:23 |
| [Linly](https://github.com/CVI-SZU/Linly) | Chinese-LLaMAåŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† | 1287 | 2023-05-05-02:28:38 |
| [Agent-LLM](https://github.com/Josh-XT/Agent-LLM) | An Artificial Intelligence Automation Platform.  AI Instruction management from various providers, has an adaptive memory, and a versatile plugin system with many commands including web browsing.  Supports many AI providers and models and growing support every day. | 1185 | 2023-05-05-02:28:48 |
| [LlamaAcademy](https://github.com/danielgross/LlamaAcademy) | A school for camelids | 1096 | 2023-05-05-00:17:17 |
| [KoAlpaca](https://github.com/Beomi/KoAlpaca) | KoAlpaca: Korean Alpaca Model based on Stanford Alpaca (feat. LLAMA and Polyglot-ko) | 928 | 2023-05-04-11:59:05 |
| [alpaca-electron](https://github.com/ItsPi3141/alpaca-electron) | The simplest way to run Alpaca (and other LLaMA-based local LLMs) on your own computer | 917 | 2023-05-05-01:33:47 |
| [LlamaChat](https://github.com/alexrozanski/LlamaChat) | Chat with your favourite LLaMA models in a native macOS app | 853 | 2023-05-05-00:43:16 |
| [pygpt4all](https://github.com/nomic-ai/pygpt4all) | Official supported Python bindings for llama.cpp + gpt4all | 842 | 2023-05-05-01:38:14 |
| [llama-chat](https://github.com/randaller/llama-chat) | Chat with Meta's LLaMA models at home made easy | 664 | 2023-05-05-00:05:50 |
| [LLaMA_MPS](https://github.com/jankais3r/LLaMA_MPS) | Run LLaMA (and Stanford-Alpaca) inference on Apple Silicon GPUs. | 505 | 2023-05-03-09:45:32 |
| [llama-lab](https://github.com/run-llama/llama-lab) | None | 484 | 2023-05-05-01:15:00 |
| [Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | Repo for HuaTuo (åé©¼), Llama-7B tuned with Chinese medical knowledge. åé©¼æ¨¡å‹ä»“åº“ï¼ŒåŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„LLaMAæ¨¡å‹æŒ‡ä»¤å¾®è°ƒ | 468 | 2023-05-05-00:11:24 |
| [ChatGenTitle](https://github.com/WangRongsheng/ChatGenTitle) | ğŸŒŸ ChatGenTitleï¼šä½¿ç”¨ç™¾ä¸‡arXivè®ºæ–‡ä¿¡æ¯åœ¨LLaMAæ¨¡å‹ä¸Šè¿›è¡Œå¾®è°ƒçš„è®ºæ–‡é¢˜ç›®ç”Ÿæˆæ¨¡å‹ | 458 | 2023-05-04-11:48:49 |
| [Chinese-alpaca-lora](https://github.com/LC1332/Chinese-alpaca-lora) | éª†é©¼:A Chinese finetuned instruction LLaMA. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ | 455 | 2023-05-04-18:25:45 |
| [minimal-llama](https://github.com/zphang/minimal-llama) | None | 381 | 2023-05-04-15:22:37 |
| [rllama](https://github.com/Noeda/rllama) | Rust+OpenCL+AVX2 implementation of LLaMA inference code | 375 | 2023-05-04-16:29:16 |
| [godot-dodo](https://github.com/minosvasilias/godot-dodo) | Finetuning large language models for GDScript generation. | 347 | 2023-05-04-21:44:45 |
| [MLE-LLaMA](https://github.com/feizc/MLE-LLaMA) | Multi-language Enhanced LLaMA | 264 | 2023-05-04-14:19:29 |
- Sort by: Updated

| Name | Description | Stars | Updated |
| --- | --- | --- | --- |
| [AiTreasureBox](https://github.com/superiorlu/AiTreasureBox) | ğŸ¤– Collect practical AI repos, tools, websites, papers and tutorials on AI. å®ç”¨çš„AIç™¾å®ç®± ğŸ’  | 92 | 2023-05-03-19:09:14 |
| [LLaVA](https://github.com/haotian-liu/LLaVA) | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. | 2149 | 2023-05-05-02:02:26 |
| [libllama-rs](https://github.com/psm14/libllama-rs) | Rust bindings for llama.cpp | 0 | 2023-04-11-00:26:28 |
| [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) | Python bindings for llama.cpp | 907 | 2023-05-05-00:25:53 |
| [MT-LLaMA](https://github.com/DAMO-NLP-SG/MT-LLaMA) | Multi-Task instruction-tuned LLaMA | 1 | 2023-05-05-01:54:56 |
| [ziptie](https://github.com/jeddyhhh/ziptie) | A web interface for llama.cpp cli written in js, jQuery and php. | 0 | 2023-04-19-02:04:44 |
| [llama_index_tests](https://github.com/eliujl/llama_index_tests) | Llama_index tests for chatting with files | 0 | 2023-05-03-04:17:39 |
| [LocalAI](https://github.com/go-skynet/LocalAI) | :robot: Self-hosted, community-driven simple local OpenAI-compatible API written in go. Can be used as a drop-in replacement for OpenAI, running on CPU with consumer-grade hardware. API for ggml compatible models, for instance: llama.cpp, alpaca.cpp, gpt4all.cpp, rwkv.cpp, vicuna, koala, gpt4all-j, cerebras | 2051 | 2023-05-05-02:26:32 |
| [exllama](https://github.com/turboderp/exllama) | A more memory-efficient rewrite of the HF transformers implementation of Llama for use with quantized weights. | 1 | 2023-05-05-01:20:48 |
| [llama-leap](https://github.com/ryanc2811/llama-leap) | None | 0 | 2023-05-02-17:12:48 |
| [llama.cpp](https://github.com/ggerganov/llama.cpp) | Port of Facebook's LLaMA model in C/C++ | 25614 | 2023-05-05-02:22:52 |
| [Dr.llama](https://github.com/zguo0525/Dr.llama) | None | 0 | 2023-05-05-00:00:10 |
| [hyv](https://github.com/failfa-st/hyv) | A "Hyv" is a group of "Agents" that work together to achieve a specific goal or set of goals. | 5 | 2023-05-02-23:45:50 |
| [llama.cpp-dotnet](https://github.com/dranger003/llama.cpp-dotnet) | C# bindings for llama.cpp and .NET core library. | 10 | 2023-05-05-00:16:13 |
| [LLaMA-Adapter](https://github.com/ZrrSkywalker/LLaMA-Adapter) | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters | 3063 | 2023-05-05-02:23:31 |
| [go-llama.cpp](https://github.com/go-skynet/go-llama.cpp) | LLama.cpp golang bindings | 93 | 2023-05-04-19:56:08 |
| [llama-chroma](https://github.com/SocialGouv/llama-chroma) | A Llama and Chroma service | 0 | 2023-04-27-15:28:11 |
| [repositorio1](https://github.com/LucasAltamira/repositorio1) | Es mi primer repositorio por eso lo llamo repositorio1, sino no lo llamaria ropositorio1 se llamaria de otra forma por ejemplo; ropositorio2 pero, como no es mi segundo repositorio no se llama repositorio2 | 0 | 2023-04-27-20:07:50 |
| [llama_ros](https://github.com/mgonzs13/llama_ros) | llama.cpp for ROS 2 | 22 | 2023-04-29-21:36:04 |
| [php-hugging-chat](https://github.com/maximerenou/php-hugging-chat) | HuggingChat PHP client (OpenAssistant's LLaMA) | 8 | 2023-04-30-13:10:58 |
| [llm-chain](https://github.com/sobelio/llm-chain) | `llm-chain` is a powerful rust crate for building chains in large language models allowing you to summarise text and complete complex tasks | 294 | 2023-05-05-01:48:37 |
| [gpt_academic](https://github.com/binary-husky/gpt_academic) | ä¸ºGPT/GLMæä¾›å›¾å½¢äº¤äº’ç•Œé¢ï¼Œç‰¹åˆ«ä¼˜åŒ–è®ºæ–‡é˜…è¯»æ¶¦è‰²ä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡æ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®&å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒä»£ç å—è¡¨æ ¼æ˜¾ç¤ºï¼ŒTexå…¬å¼åŒæ˜¾ç¤ºï¼Œæ–°å¢Pythonå’ŒC++é¡¹ç›®å‰–æ&è‡ªè¯‘è§£åŠŸèƒ½ï¼ŒPDF/LaTexè®ºæ–‡ç¿»è¯‘&æ€»ç»“åŠŸèƒ½ï¼Œæ”¯æŒå¹¶è¡Œé—®è¯¢å¤šç§LLMæ¨¡å‹ï¼Œæ”¯æŒæ¸…åchatglmç­‰æœ¬åœ°æ¨¡å‹ã€‚å…¼å®¹llama,rwkv,ç›˜å¤å¤§æ¨¡å‹ç­‰ã€‚ | 31835 | 2023-05-05-02:30:01 |
| [Personal-GPTQ-for-LLaMa-Builds-for-Linux](https://github.com/MuXodious/Personal-GPTQ-for-LLaMa-Builds-for-Linux) | None | 0 | 2023-05-04-21:52:03 |
| [LlamaGPTJ-chat](https://github.com/kuvaus/LlamaGPTJ-chat) | Simple chat program for both LLaMa and GPT-J models | 17 | 2023-05-05-00:21:37 |
| [Agent-LLM](https://github.com/Josh-XT/Agent-LLM) | An Artificial Intelligence Automation Platform.  AI Instruction management from various providers, has an adaptive memory, and a versatile plugin system with many commands including web browsing.  Supports many AI providers and models and growing support every day. | 1185 | 2023-05-05-02:28:48 |
| [llama-dfdx](https://github.com/coreylowman/llama-dfdx) | LLaMa 7b with CUDA acceleration implemented in rust. Minimal GPU memory needed! | 13 | 2023-05-03-13:38:12 |
| [cadmancer](https://github.com/Algomancer/cadmancer) | Linguistic Labyrinths Linger, Llama Legends Loom | 1 | 2023-05-03-07:04:33 |
| [Espritchatbot-RASA-RWKV](https://github.com/kimou6055/Espritchatbot-RASA-RWKV) | This is a chatbot designed to answer questions about Esprit University. It was created by a group of Esprit's Students called INNOVISION using the Rasa framework.  The unindexed intents are generated using the RWKV-4-Raven | 3 | 2023-05-02-02:58:03 |
| [lit-llama](https://github.com/Lightning-AI/lit-llama) | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. | 3022 | 2023-05-05-02:05:40 |
| [pandallm](https://github.com/dandelionsllm/pandallm) | Panda: æµ·å¤–ä¸­æ–‡å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Llama-7B, -13B, -33B, -65B è¿›è¡Œä¸­æ–‡é¢†åŸŸä¸Šçš„æŒç»­é¢„è®­ç»ƒã€‚ | 111 | 2023-05-05-02:10:14 |
